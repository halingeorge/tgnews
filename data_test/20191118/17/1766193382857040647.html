<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/newsticker/meldung/Groq-KI-Prozessor-schafft-eine-Billiarde-Operationen-pro-Sekunde-4589456.html"/>
    <meta property="og:site_name" content="c't Magazin"/>
    <meta property="article:published_time" content="2019-11-18T17:35:00+00:00"/>
    <meta property="og:title" content="Groq: KI-Prozessor schafft eine Billiarde Operationen pro Sekunde"/>
    <meta property="og:description" content="Der neuartige Tensor Streaming Processor des Start-ups Groq verarbeitet KI-Algorithmen mit bis zu 1 Peta-Ops/s."/>
  </head>
  <body>
    <article>
      <h1>Groq: KI-Prozessor schafft eine Billiarde Operationen pro Sekunde</h1>
      <h2>Der neuartige Tensor Streaming Processor des Start-ups Groq verarbeitet KI-Algorithmen mit bis zu 1 Peta-Ops/s.</h2>
      <address><time datetime="2019-11-18T17:35:00+00:00">18 Nov 2019, 17:35</time> by <a rel="author">Christof Windeck</a></address>
      <p>Das Start-up Groq aus dem Silicon Valley hat einen Tensor Streaming Processor (TSP) mit neuartiger Mikroarchitektur entwickelt, der bestimmte KI-Algorithmen mit einer Billiarde Operationen pro Sekunde verarbeiten soll. Muster des TSP sind nach Firmenangaben bereits bei Pilotkunden im Testbetrieb. Der TSP sitzt auf einer PCI-Express-Karte, ist also zum Einsatz als Rechenbeschleuniger in Servern gedacht.</p>
      <p>Junge Firmen, die Spezialprozessoren für KI- und Machine-Learning-Algorithmen entwickeln, schießen wie Pilze aus dem Boden. Offenbar ist es relativ einfach, bei Finanzinvestoren Risikokapital für KI-Chips einzuwerben. Groq kann mit seiner Gründer-Riege und erfahrenen Experten punkten: Jonathan Ross war an der Entwicklung von <a href="https://www.heise.de/meldung/Kuenstliche-Intelligenz-Architektur-und-Performance-von-Googles-KI-Chip-TPU-3676312.html">Googles Tensor Processing Units</a> (TPUs) beteiligt, die mittlerweile in dritter Generation als <a href="https://www.heise.de/meldung/Nitro-Corsica-TPU-Spezial-Hardware-in-Rechenzentren-4499997.html">TPU v3</a> in Googles Cloud rechnen. Michelle Tomasko war zuvor bei Nvidia und Google, Dale Southard war Principal System Architect für Nividia Tesla.</p>
      <h3>Neuartige Mikroarchitektur</h3>
      <p><a href="https://groq.com/groq-announces-worlds-first-architecture-capable-of-petaops-on-a-single-chip/">Groq setzt nach eigenen Angaben auf eine neuartige Mikroarchitektur</a>, bei der Software beziehungsweise ein spezieller Compiler die wesentliche Rolle spielt. Dadurch lässt sich laut Groq eine Menge Siliziumfläche einsparen, damit möglichst viele Transistoren des TSP tatsächlich auch Nutzwert liefern.</p>
      <p>Bei welcher Genauigkeit der TSP auf 1 PetaOps/s kommt, verrät Groq bisher allerdings nicht; INT8 wäre ein wahrscheinlicher Wert. Bei Gleitkommaberechnungen (Floating Point) soll der Groq-TSP bis zu 250 TFlops erreichen; auch hier fehlt eine Angabe wie FP16 oder BFloat.</p>
      <p>Groq verspricht erhebliche Vorteile im Vergleich zu Prozessoren und GPUs mit KI-Erweiterungen sowie zu FPGA-Chips, legt aber bisher keine konkreten Vergleichswerte etwa mit dem MLPerf-Benchmark vor. Wegen der raschen Fortschritte auch bei den Algorithmen selbst ist ein Leistungsvergleich zu Konkurrenten wie Nvidia (<a href="https://www.heise.de/meldung/Tesla-V100-Nvidia-uebergibt-erste-Volta-Rechenkarten-an-Deep-Learning-Forscher-3781130.html">Tesla V100</a>/<a href="https://www.heise.de/meldung/Nvidia-sieht-sich-bei-KI-Chips-in-Fuehrung-und-bringt-Roboter-Rechenmodul-4578623.html">Xavier</a>), Intel (Xeon, <a href="https://www.heise.de/meldung/Intels-KI-Beschleuniger-NNP-T-mit-PCIe-4-0-und-TSMC-Technik-4503082.html">NNP-T1000</a>, NNP-I1000, Mobileye Eyeq, Movidius <a href="https://www.heise.de/meldung/Intel-stellt-Vektorprozessor-fuer-KI-Algorithmen-in-der-Bildverarbeitung-vor-3814283.html">Myriad</a>, Stratix), AMD (<a href="https://www.heise.de/meldung/AMD-Radeon-Instinct-MI50-und-MI60-PCIe-4-0-Beschleuniger-mit-7-nm-GPU-4213910.html">Radeon Instinct</a>), Habana (<a href="https://www.heise.de/select/ct/2019/5/1551439059879983">Goya</a>), Huawei (<a href="https://www.heise.de/meldung/Huawei-Ascend-910-256-TeraFlops-Prozessor-fuer-KI-4503849.html">Ascend</a>), Alibaba (<a href="https://www.heise.de/tr/artikel/KI-nesische-Aufholjagd-4502117.html">Hanguang/Pingtouge</a>), Tesla (<a href="https://www.heise.de/meldung/KI-fuer-autonomes-Fahren-Teslas-FSD-Chip-vereint-CPU-GPU-und-KI-Prozessor-4408291.html">FSD</a>), Xilinx (<a href="https://www.heise.de/meldung/Flexible-und-billigere-FPGA-Beschleuniger-fuer-Server-4489678.html">Alveo</a>/Versal), <a href="https://www.heise.de/meldung/Cerebras-stellt-Wafer-grossen-KI-Chip-vor-4500723.html">Cerebras</a>, <a href="https://www.heise.de/meldung/KI-Spezialist-Wave-Computing-kauft-MIPS-4080057.html">Wave Computing</a>, <a href="https://www.heise.de/meldung/Hot-Chips-KI-Beschleuniger-mit-analogem-Flash-Speicher-4143071.html">Mythic</a>, <a href="https://www.heise.de/meldung/KI-Chips-aus-Frankreich-fuer-Autos-Flugzeuge-und-Waffen-4300666.html">Kalray</a>, LeapMind, Prophesee, Micron (Fwdnxt) oder auch Graphcore (<a href="https://www.heise.de/meldung/35-Milliarden-Transistoren-Riesen-Chip-Xilinx-VU19P-4502878.html">Colossus</a>) schwierig. (<a href="mailto:ciw@ct.de">ciw</a>)</p>
    </article>
  </body>
</html>